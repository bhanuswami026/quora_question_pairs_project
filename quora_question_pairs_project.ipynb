{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quora_question_pairs_project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BXRBsldqowjE"
      ],
      "mount_file_id": "1nefOzKhwfP9b9doVfrq0fek6qytfaOgu",
      "authorship_tag": "ABX9TyNc1i9o1xVFw2mCvQ9jfjW2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgIaZUKfhaCa"
      },
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from subprocess import check_output\n",
        "%matplotlib inline\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "import plotly.tools as tls\n",
        "import gc\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "!pip install distance\n",
        "import distance\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXRBsldqowjE"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxREwXd_oumh"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Datasets/train_quora.csv\")\n",
        "\n",
        "print(\"Number of data points:\",df.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q2F63QIpSlz"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rniP4UYMpXPV"
      },
      "source": [
        "df.info()\n",
        "# There are 3 rows in total with missing values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoekXKO7vKa9"
      },
      "source": [
        "# List of rows with missing values\n",
        "nan_rows = df[df.isnull().any(1)]\n",
        "print (nan_rows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPQWUzaGvJsy"
      },
      "source": [
        "# Putting a space at missing value space\n",
        "df = df.fillna('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsSSFvZLp_6v"
      },
      "source": [
        "df.is_duplicate.value_counts().plot.bar()\n",
        "# 0 values are much more than 1 values\n",
        "print (df.is_duplicate.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7AVau3oqI2l"
      },
      "source": [
        "#checking whether there are any repeated pair of questions\n",
        "\n",
        "pair_duplicates = df[['qid1','qid2','is_duplicate']].groupby(['qid1','qid2']).count().reset_index()\n",
        "\n",
        "print (\"Number of duplicate questions\",(pair_duplicates).shape[0] - df.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjCrf0dMXQcG"
      },
      "source": [
        "# FEATURE GENERATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHqkqqrTueHB"
      },
      "source": [
        "#freq_qid1 = Frequency of qid1's\n",
        "#freq_qid2 = Frequency of qid2's\n",
        "df['freq_qid1'] = df.groupby('qid1')['qid1'].transform('count') \n",
        "df['freq_qid2'] = df.groupby('qid2')['qid2'].transform('count')\n",
        "\n",
        "#q1len = Length of q1\n",
        "#q2len = Length of q2\n",
        "df['q1len'] = df['question1'].str.len() \n",
        "df['q2len'] = df['question2'].str.len()\n",
        "\n",
        "#q1_n_words = Number of words in Question 1\n",
        "#q2_n_words = Number of words in Question 2\n",
        "df['q1_n_words'] = df['question1'].apply(lambda row: len(row.split(\" \")))\n",
        "df['q2_n_words'] = df['question2'].apply(lambda row: len(row.split(\" \")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDYqkHOXuf2G"
      },
      "source": [
        "#word_Common = (Number of common unique words in Question 1 and Question 2)\n",
        "def normalized_word_Common(row):\n",
        "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
        "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
        "    return 1.0 * len(w1 & w2)\n",
        "df['word_Common'] = df.apply(normalized_word_Common, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjQ1vXx7XmH6"
      },
      "source": [
        "#word_Total =(Total num of words in Question 1 + Total num of words in Question 2)\n",
        "def normalized_word_Total(row):\n",
        "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
        "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
        "    return 1.0 * (len(w1) + len(w2))\n",
        "df['word_Total'] = df.apply(normalized_word_Total, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3j_XSblXphW"
      },
      "source": [
        "#word_share = (word_common)/(word_Total)\n",
        "def normalized_word_share(row):\n",
        "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
        "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
        "    return 1.0 * len(w1 & w2)/(len(w1) + len(w2))\n",
        "df['word_share'] = df.apply(normalized_word_share, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-horkHU0XrAt"
      },
      "source": [
        "#freq_q1+freq_q2 = sum total of frequency of qid1 and qid2\n",
        "#freq_q1-freq_q2 = absolute difference of frequency of qid1 and qid2\n",
        "df['freq_q1+q2'] = df['freq_qid1']+df['freq_qid2']\n",
        "df['freq_q1-q2'] = abs(df['freq_qid1']-df['freq_qid2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LjYIRg-Xsj1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6p64u9kXtig"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb6uQitCeeFF"
      },
      "source": [
        "# TEXT DATA PRE-PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciZrFVDzeh64"
      },
      "source": [
        "#import libraries\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from subprocess import check_output\n",
        "%matplotlib inline\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "import plotly.tools as tls\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import distance\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import distance\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "!pip install fuzzywuzzy\n",
        "from fuzzywuzzy import fuzz\n",
        "from sklearn.manifold import TSNE\n",
        "# Import the Required lib packages for WORD-Cloud generation\n",
        "# https://stackoverflow.com/questions/45625434/how-to-install-wordcloud-in-python3-6\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from os import path\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn9xplZhfVR5"
      },
      "source": [
        "# Removing html tags\n",
        "# Removing Punctuations\n",
        "# Performing stemming\n",
        "# Removing Stopwords\n",
        "# Expanding contractions etc.\n",
        "\n",
        "# To get the results in 4 decemal points\n",
        "SAFE_DIV = 0.0001 \n",
        "\n",
        "STOP_WORDS = stopwords.words(\"english\")\n",
        "\n",
        "\n",
        "def preprocess(x):\n",
        "    x = str(x).lower()\n",
        "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
        "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
        "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
        "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
        "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
        "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
        "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
        "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
        "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
        "    \n",
        "    \n",
        "    porter = PorterStemmer()\n",
        "    pattern = re.compile('\\W')\n",
        "    \n",
        "    if type(x) == type(''):\n",
        "        x = re.sub(pattern, ' ', x)\n",
        "    \n",
        "    \n",
        "    if type(x) == type(''):\n",
        "        x = porter.stem(x)\n",
        "        example1 = BeautifulSoup(x)\n",
        "        x = example1.get_text()\n",
        "               \n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY9IvX8OgVBN"
      },
      "source": [
        "# TEXT FEATURE EXTRACTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIC-dm5Sg1-K"
      },
      "source": [
        "Definition:\n",
        "- __Token__: You get a token by splitting sentence a space\n",
        "- __Stop_Word__ : stop words as per NLTK.\n",
        "- __Word__ : A token that is not a stop_word\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22BAzrl5gH7k"
      },
      "source": [
        "def get_token_features(q1, q2):\n",
        "    token_features = [0.0]*10\n",
        "    \n",
        "    # Converting the Sentence into Tokens: \n",
        "    q1_tokens = q1.split()\n",
        "    q2_tokens = q2.split()\n",
        "\n",
        "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
        "        return token_features\n",
        "    # Get the non-stopwords in Questions\n",
        "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
        "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
        "    \n",
        "    #Get the stopwords in Questions\n",
        "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
        "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
        "    \n",
        "    # Get the common non-stopwords from Question pair\n",
        "    common_word_count = len(q1_words.intersection(q2_words))\n",
        "    \n",
        "    # Get the common stopwords from Question pair\n",
        "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
        "    \n",
        "    # Get the common Tokens from Question pair\n",
        "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
        "    \n",
        "    #cwc_min : Ratio of common_word_count to min lenghth of word count of Q1 and Q2\n",
        "    #cwc_min = common_word_count / (min(len(q1_words), len(q2_words))\n",
        "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
        "    #cwc_max : Ratio of common_word_count to max lenghth of word count of Q1 and Q2\n",
        "    #cwc_max = common_word_count / (max(len(q1_words), len(q2_words))\n",
        "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
        "    # csc_min : Ratio of common_stop_count to min lenghth of stop count of Q1 and Q2 \n",
        "    # csc_min = common_stop_count / (min(len(q1_stops), len(q2_stops))\n",
        "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
        "    #csc_max : Ratio of common_stop_count to max lenghth of stop count of Q1 and Q2\n",
        "    #csc_max = common_stop_count / (max(len(q1_stops), len(q2_stops))\n",
        "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
        "    # ctc_min : Ratio of common_token_count to min lenghth of token count of Q1 and Q2\n",
        "    # ctc_min = common_token_count / (min(len(q1_tokens), len(q2_tokens))\n",
        "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
        "    #ctc_max : Ratio of common_token_count to max lenghth of token count of Q1 and Q2\n",
        "    #ctc_max = common_token_count / (max(len(q1_tokens), len(q2_tokens))\n",
        "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
        "    \n",
        "    # Last word of both question is same or not\n",
        "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
        "    \n",
        "    # First word of both question is same or not\n",
        "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
        "    \n",
        "    #abs_len_diff : Abs. length difference\n",
        "    #abs_len_diff = abs(len(q1_tokens) - len(q2_tokens))\n",
        "    token_features[8] = abs(len(q1_tokens) - len(q2_tokens))\n",
        "    \n",
        "    #Average Token Length of both Questions\n",
        "    token_features[9] = (len(q1_tokens) + len(q2_tokens))/2\n",
        "    return token_features\n",
        "\n",
        "# get the Longest Common sub string\n",
        "\n",
        "def get_longest_substr_ratio(a, b):\n",
        "    strs = list(distance.lcsubstrings(a, b))\n",
        "    if len(strs) == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return len(strs[0]) / (min(len(a), len(b)) + 1)\n",
        "\n",
        "def extract_features(df):\n",
        "    # preprocessing each question\n",
        "    df[\"question1\"] = df[\"question1\"].fillna(\"\").apply(preprocess)\n",
        "    df[\"question2\"] = df[\"question2\"].fillna(\"\").apply(preprocess)\n",
        "\n",
        "    print(\"token features...\")\n",
        "    \n",
        "    # Merging Features with dataset\n",
        "    \n",
        "    token_features = df.apply(lambda x: get_token_features(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    \n",
        "    df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\n",
        "    df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\n",
        "    df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\n",
        "    df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\n",
        "    df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\n",
        "    df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\n",
        "    df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\n",
        "    df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))\n",
        "    df[\"abs_len_diff\"]  = list(map(lambda x: x[8], token_features))\n",
        "    df[\"mean_len\"]      = list(map(lambda x: x[9], token_features))\n",
        "   \n",
        "    #Computing Fuzzy Features and Merging with Dataset\n",
        "    print(\"fuzzy features..\")\n",
        "\n",
        "    df[\"token_set_ratio\"]       = df.apply(lambda x: fuzz.token_set_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    # The token sort approach involves tokenizing the string in question, sorting the tokens alphabetically, and \n",
        "    # then joining them back into a string We then compare the transformed strings with a simple ratio().\n",
        "    df[\"token_sort_ratio\"]      = df.apply(lambda x: fuzz.token_sort_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    df[\"fuzz_ratio\"]            = df.apply(lambda x: fuzz.QRatio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    df[\"fuzz_partial_ratio\"]    = df.apply(lambda x: fuzz.partial_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    df[\"longest_substr_ratio\"]  = df.apply(lambda x: get_longest_substr_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05jnGqxDjRJG"
      },
      "source": [
        "df = extract_features(df)\n",
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdaqj-edjUfY"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flot1wg8sdZP"
      },
      "source": [
        "# Word2VEC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdyUwJRyro7m"
      },
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tqdm import tqdm\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBZm0BH7tCdJ"
      },
      "source": [
        "# encode questions to unicode\n",
        "df['question1'] = df['question1'].apply(lambda x: str(x))\n",
        "df['question2'] = df['question2'].apply(lambda x: str(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYCub2tgtOpI"
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfgd-R-ktSRc"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# merge texts\n",
        "questions = list(df['question1']) + list(df['question2'])\n",
        "\n",
        "tfidf = TfidfVectorizer(lowercase=False )\n",
        "tfidf.fit_transform(questions)\n",
        "\n",
        "# dict key:word and value:tf-idf score\n",
        "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcMt4CYYtluN"
      },
      "source": [
        "# en_vectors_web_lg, which includes over 1 million unique vectors.\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "vecs1 = []\n",
        "\n",
        "for qu1 in tqdm(list(df['question1'])):\n",
        "    doc1 = nlp(qu1) \n",
        "    # 384 is the number of dimensions of vectors \n",
        "    mean_vec1 = np.zeros([len(doc1), 384])\n",
        "    for word1 in doc1:\n",
        "        # word2vec\n",
        "        vec1 = word1.vector\n",
        "        # fetch df score\n",
        "        try:\n",
        "            idf = word2tfidf[str(word1)]\n",
        "        except:\n",
        "            idf = 0\n",
        "        # compute final vec\n",
        "        mean_vec1 += vec1 * idf\n",
        "    mean_vec1 = mean_vec1.mean(axis=0)\n",
        "    vecs1.append(mean_vec1)\n",
        "df['q1_feats_m'] = list(vecs1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haxf_DOPunZ1"
      },
      "source": [
        "vecs2 = []\n",
        "for qu2 in tqdm(list(df['question2'])):\n",
        "    doc2 = nlp(qu2) \n",
        "    mean_vec2 = np.zeros([len(doc2), 384])\n",
        "    for word2 in doc2:\n",
        "        # word2vec\n",
        "        vec2 = word2.vector\n",
        "        # fetch df score\n",
        "        try:\n",
        "            idf = word2tfidf[str(word2)]\n",
        "        except:\n",
        "            #print word\n",
        "            idf = 0\n",
        "        # compute final vec\n",
        "        mean_vec2 += vec2 * idf\n",
        "    mean_vec2 = mean_vec2.mean(axis=0)\n",
        "    vecs2.append(mean_vec2)\n",
        "df['q2_feats_m'] = list(vecs2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7VxXwTwuvy3"
      },
      "source": [
        "df1 = dfnlp.drop(['qid1','qid2','question1','question2'],axis=1)\n",
        "df2 = dfppro.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
        "df3 = df.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
        "df3_q1 = pd.DataFrame(df3.q1_feats_m.values.tolist(), index= df3.index)\n",
        "df3_q2 = pd.DataFrame(df3.q2_feats_m.values.tolist(), index= df3.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41XGQdNBu4CK"
      },
      "source": [
        "df3_q1['id']=df1['id']\n",
        "df3_q2['id']=df1['id']\n",
        "df1  = df1.merge(df2, on='id',how='left')\n",
        "df2  = df3_q1.merge(df3_q2, on='id',how='left')\n",
        "data  = df1.merge(df2, on='id',how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntm8w5HUvJlw"
      },
      "source": [
        "# GETTING READY FOR MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHpSQmyAu_2f"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics.classification import accuracy_score, log_loss\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold \n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import math\n",
        "from sklearn.metrics import normalized_mutual_info_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, auc, roc_curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xziU1o2LvOOf"
      },
      "source": [
        "# remove the first row \n",
        "data.drop(data.index[0], inplace=True)\n",
        "y_true = data['is_duplicate']\n",
        "data.drop(['Unnamed: 0', 'id','index','is_duplicate'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOTUY-zmw_z3"
      },
      "source": [
        "### TRAIN-TEST-SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvg_AREOw_SB"
      },
      "source": [
        "X_train,X_test, y_train, y_test = train_test_split(data, y_true, stratify=y_true, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ4QWvEew0Ur"
      },
      "source": [
        "# function to plot confusion matrix\n",
        "def plot_confusion_matrix(test_y, predict_y):\n",
        "    C = confusion_matrix(test_y, predict_y)\n",
        "    # for precision matrix\n",
        "    A =(((C.T)/(C.sum(axis=1))).T)\n",
        "    # for recall marix\n",
        "    B =(C/C.sum(axis=0))\n",
        "\n",
        "    plt.figure(figsize=(20,4))\n",
        "    \n",
        "    labels = [1,2]\n",
        "    # representing A in heatmap format\n",
        "    cmap=sns.light_palette(\"blue\")\n",
        "    plt.subplot(1, 3, 1)\n",
        "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('Original Class')\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    \n",
        "    plt.subplot(1, 3, 2)\n",
        "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('Original Class')\n",
        "    plt.title(\"Precision matrix\")\n",
        "    \n",
        "    plt.subplot(1, 3, 3)\n",
        "    # representing B in heatmap format\n",
        "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('Original Class')\n",
        "    plt.title(\"Recall matrix\")\n",
        "    \n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0CqA_IFxvCg"
      },
      "source": [
        "# BUILDING THE RANDOM MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgZXOvqWxbmO"
      },
      "source": [
        "predicted_y = np.zeros((test_len,2))\n",
        "for i in range(test_len):\n",
        "    rand_probs = np.random.rand(1,2)\n",
        "    predicted_y[i] = ((rand_probs/sum(sum(rand_probs)))[0])\n",
        "print(\"Log loss on Test Data using Random Model\",log_loss(y_test, predicted_y, eps=1e-15))\n",
        "\n",
        "predicted_y =np.argmax(predicted_y, axis=1)\n",
        "plot_confusion_matrix(y_test, predicted_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bGC6J_Px5hY"
      },
      "source": [
        "# LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ioLz79Lx0mW"
      },
      "source": [
        "alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
        "\n",
        "log_error_array=[]\n",
        "for i in alpha:\n",
        "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
        "    sig_clf.fit(X_train, y_train)\n",
        "    predict_y = sig_clf.predict_proba(X_test)\n",
        "    log_error_array.append(log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n",
        "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n",
        "\n",
        "best_alpha = np.argmin(log_error_array)\n",
        "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
        "sig_clf.fit(X_train, y_train)\n",
        "\n",
        "predict_y = sig_clf.predict_proba(X_train)\n",
        "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
        "predict_y = sig_clf.predict_proba(X_test)\n",
        "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n",
        "predicted_y =np.argmax(predict_y,axis=1)\n",
        "print(\"Total number of data points :\", len(predicted_y))\n",
        "plot_confusion_matrix(y_test, predicted_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN1_eOY7yVoM"
      },
      "source": [
        "# XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvWHI0hZyUvX"
      },
      "source": [
        "import xgboost as xgb\n",
        "params = {}\n",
        "params['objective'] = 'binary:logistic'\n",
        "params['eval_metric'] = 'logloss'\n",
        "params['eta'] = 0.02\n",
        "params['max_depth'] = 4\n",
        "\n",
        "d_train = xgb.DMatrix(X_train, label=y_train)\n",
        "d_test = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "watchlist = [(d_train, 'train'), (d_test, 'valid')]\n",
        "\n",
        "bst = xgb.train(params, d_train, 400, watchlist, early_stopping_rounds=20, verbose_eval=10)\n",
        "\n",
        "xgdmat = xgb.DMatrix(X_train,y_train)\n",
        "predict_y = bst.predict(d_test)\n",
        "print(\"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSEYFEbXyGPy"
      },
      "source": [
        "predicted_y =np.array(predict_y>0.5,dtype=int)\n",
        "print(\"Total number of data points :\", len(predicted_y))\n",
        "plot_confusion_matrix(y_test, predicted_y)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}